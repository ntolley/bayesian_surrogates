{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import hnn_core\n",
    "from hnn_core import calcium_model, simulate_dipole, read_params, pick_connection\n",
    "from hnn_core.network_models import add_erp_drives_to_jones_model\n",
    "from hnn_core.network_builder import NetworkBuilder\n",
    "from hnn_core.cell import _get_gaussian_connection\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import utils\n",
    "from utils import (SingleNeuron_Data, Network_Data, CellType_Dataset_Fast,\n",
    "                   linear_scale_forward, log_scale_forward, UniformPrior, beta_tuning_param_function)\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "# device = torch.device(\"cuda:0\")\n",
    "device = 'cpu'\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = calcium_model()\n",
    "\n",
    "# Extract all E-I connection types\n",
    "E_gids = np.concatenate([net.gid_ranges['L2_pyramidal'], net.gid_ranges['L5_pyramidal']]).tolist()\n",
    "I_gids = np.concatenate([net.gid_ranges['L2_basket'], net.gid_ranges['L5_basket']]).tolist()\n",
    "\n",
    "EI_connections = pick_connection(net, src_gids=E_gids, target_gids=I_gids)\n",
    "EE_connections = pick_connection(net, src_gids=E_gids, target_gids=E_gids)\n",
    "II_connections = pick_connection(net, src_gids=I_gids, target_gids=I_gids)\n",
    "IE_connections = pick_connection(net, src_gids=I_gids, target_gids=E_gids)\n",
    "\n",
    "# Store in dictionary to be added to theta_dict\n",
    "theta_extra = {'EI_connections': EI_connections, 'EE_connections': EE_connections, \n",
    "               'II_connections': II_connections, 'IE_connections': IE_connections,\n",
    "               'lamtha': 4.0}\n",
    "\n",
    "prior_dict = {'EI_gscale': {'bounds': (-2, 2), 'rescale_function': log_scale_forward},\n",
    "              'EE_gscale': {'bounds': (-2, 2), 'rescale_function': log_scale_forward},\n",
    "              'II_gscale': {'bounds': (-2, 2), 'rescale_function': log_scale_forward},\n",
    "              'IE_gscale': {'bounds': (-2, 2), 'rescale_function': log_scale_forward},\n",
    "              'EI_prob': {'bounds': (0, 1), 'rescale_function': linear_scale_forward},\n",
    "              'EE_prob': {'bounds': (0, 1), 'rescale_function': linear_scale_forward},\n",
    "              'II_prob': {'bounds': (0, 1), 'rescale_function': linear_scale_forward},\n",
    "              'IE_prob': {'bounds': (0, 1), 'rescale_function': linear_scale_forward},\n",
    "              'L2e_distal': {'bounds': (-4, 0), 'rescale_function': log_scale_forward},\n",
    "              'L2i_distal': {'bounds': (-4, 0), 'rescale_function': log_scale_forward},\n",
    "              'L5e_distal': {'bounds': (-4, 0), 'rescale_function': log_scale_forward},\n",
    "              'L5i_distal': {'bounds': (-4, 0), 'rescale_function': log_scale_forward},\n",
    "              'L2e_proximal': {'bounds': (-4, 0), 'rescale_function': log_scale_forward},\n",
    "              'L2i_proximal': {'bounds': (-4, 0), 'rescale_function': log_scale_forward},\n",
    "              'L5e_proximal': {'bounds': (-4, 0), 'rescale_function': log_scale_forward},\n",
    "              'L5i_proximal': {'bounds': (-4, 0), 'rescale_function': log_scale_forward},\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sims = 100\n",
    "prior = UniformPrior(parameters=list(prior_dict.keys()))\n",
    "theta_samples = prior.sample((n_sims,))\n",
    "theta_samples[0,:] = torch.from_numpy(np.repeat(0.5, theta_samples.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hnn(thetai, sample_idx, prior_dict, transform_dict=None):\n",
    "    theta_dict = {param_name: param_dict['rescale_function'](thetai[param_idx].numpy(), param_dict['bounds']) for \n",
    "                    param_idx, (param_name, param_dict) in enumerate(prior_dict.items())}\n",
    "    theta_extra['sample_idx'] =  sample_idx\n",
    "    theta_dict['theta_extra'] = theta_extra\n",
    "\n",
    "    hnn_core_root = op.dirname(hnn_core.__file__)\n",
    "    params_fname = op.join(hnn_core_root, 'param', 'default.json')\n",
    "    params = read_params(params_fname)\n",
    "    params.update({'N_pyr_x': 3, 'N_pyr_y': 3})\n",
    "    \n",
    "    net = calcium_model(params)\n",
    "\n",
    "    beta_tuning_param_function(net, theta_dict)\n",
    "    dpl = simulate_dipole(net, dt=0.5, tstop=1000, record_vsec='all', record_isec='all', record_dcell=True)\n",
    "\n",
    "    g = net.cell_response.plot_spikes_raster()\n",
    "    g.savefig(f'datasets/raster_plots/raster_{sample_idx}.png')\n",
    "    plt.close()\n",
    "\n",
    "    g = dpl[0].plot()\n",
    "    g.savefig(f'datasets/dipole_plots/dipole_{sample_idx}.png')\n",
    "    plt.close()\n",
    "\n",
    "    g = dpl[0].plot_psd(fmin=0, fmax=100)\n",
    "    g.savefig(f'datasets/psd_plots/psd_{sample_idx}.png')\n",
    "    plt.close()\n",
    "\n",
    "    np.save(f'datasets/dipole_data/dipole_{sample_idx}.npy', dpl[0].data['agg'], )\n",
    "\n",
    "    for cell_type in net.cell_types.keys():\n",
    "        if transform_dict is None:\n",
    "            input_spike_scaler, vsec_scaler, isec_scaler = None, None, None\n",
    "        else:\n",
    "            input_spike_scaler = transform_dict[cell_type]['input_spike_scaler']\n",
    "            vsec_scaler = transform_dict[cell_type]['vsec_scaler']\n",
    "            isec_scaler = transform_dict[cell_type]['isec_scaler']\n",
    "\n",
    "        training_set = utils.CellType_Dataset_Fast(\n",
    "            net, cell_type=cell_type, window_size=500, data_step_size=500,\n",
    "            input_spike_scaler=input_spike_scaler, vsec_scaler=vsec_scaler, isec_scaler=isec_scaler,\n",
    "            soma_filter=True, device='cpu')\n",
    "        torch.save(training_set, f'datasets/training_data/{cell_type}_dataset_{sample_idx}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "run_hnn(theta_samples[0, :], 0, prior_dict, transform_dict=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {}\n",
    "for cell_type in net.cell_types.keys():\n",
    "    dataset = torch.load(f'datasets/training_data/{cell_type}_dataset_0.pt')\n",
    "    transform_dict[cell_type] = {'input_spike_scaler': dataset.input_spike_scaler,\n",
    "                                 'vsec_scaler': dataset.vsec_scaler,\n",
    "                                 'isec_scaler': dataset.isec_scaler}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Skip first sample which is used for creating transforms\n",
    "Parallel(n_jobs=1)(delayed(run_hnn)(thetai, sample_idx+1, prior_dict, transform_dict) for (sample_idx, thetai) in enumerate(theta_samples[1:, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b48ab3240dc41ffa029ce879fa5e087e0a83cbe7a72ef65a19cb71535771faa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
