{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0665e95-c3fa-49a3-ab73-3af883dae303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no DISPLAY environment variable.\n",
      "--No graphics will be displayed.\n"
     ]
    }
   ],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import hnn_core\n",
    "from hnn_core import calcium_model, simulate_dipole, read_params\n",
    "from hnn_core.network_models import add_erp_drives_to_jones_model\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import utils\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "363edaf5-0538-4657-8541-d2937d29dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM/GRU architecture for decoding\n",
    "class model_lstm(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim=10, n_layers=2, dropout=0.1, device='cpu', bidirectional=False):\n",
    "        super(model_lstm, self).__init__()\n",
    "\n",
    "        #multiplier based on bidirectional parameter\n",
    "        if bidirectional:\n",
    "            num_directions = 2\n",
    "        else:\n",
    "            num_directions = 1\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers * num_directions\n",
    "        self.device = device\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        #Defining the layers\n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True, dropout=dropout)   \n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim*num_directions, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous()\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        weight = next(self.parameters()).data.to(self.device)\n",
    "\n",
    "        # LSTM cell initialization\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device))\n",
    "    \n",
    "\n",
    "        return hidden\n",
    "\n",
    "\n",
    "def add_noise(net):\n",
    "    rate = 10\n",
    "    weight = 0.01\n",
    "    # Add Poisson drives\n",
    "    weights_ampa_d1 = {'L2_pyramidal': weight, 'L5_pyramidal': weight,\n",
    "                       'L2_basket': weight}\n",
    "    rates_d1 = {'L2_pyramidal': rate, 'L5_pyramidal': rate, 'L2_basket': rate}\n",
    "\n",
    "    net.add_poisson_drive(\n",
    "        name='distal', tstart=0, tstop=None, rate_constant=rates_d1, location='distal', n_drive_cells='n_cells',\n",
    "        cell_specific=True, weights_ampa=weights_ampa_d1, weights_nmda=None, space_constant=1e50,\n",
    "        synaptic_delays=0.0, probability=1.0, event_seed=1, conn_seed=2)\n",
    "\n",
    "    weights_ampa_p1 = {'L2_pyramidal': weight, 'L5_pyramidal': weight,\n",
    "                       'L2_basket': weight, 'L5_basket': weight}\n",
    "    rates_p1 = {'L2_pyramidal': rate, 'L5_pyramidal': rate, 'L2_basket': rate, 'L5_basket': rate}\n",
    "\n",
    "    net.add_poisson_drive(\n",
    "        name='proximal', tstart=0, tstop=None, rate_constant=rates_p1, location='proximal', n_drive_cells='n_cells',\n",
    "        cell_specific=True, weights_ampa=weights_ampa_p1, weights_nmda=None, space_constant=1e50,\n",
    "        synaptic_delays=0.0, probability=1.0, event_seed=3, conn_seed=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f4a936f-7272-43e2-a14b-77de16f58515",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "hnn_core_root = op.dirname(hnn_core.__file__)\n",
    "params_fname = op.join(hnn_core_root, 'param', 'default.json')\n",
    "params = read_params(params_fname)\n",
    "params.update({'N_pyr_x': 1, 'N_pyr_y': 1})\n",
    "net = calcium_model(params)\n",
    "add_noise(net)\n",
    "dpl = simulate_dipole(net, dt=0.05, tstop=1000, record_vsec='all', record_isec='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66611eaa-f1e3-42aa-a7d9-90c81f76c6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70a24665-9c3b-4392-91a9-8aa62a13b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = 'L5_pyramidal'\n",
    "cell_gids = net.gid_ranges[cell_type]\n",
    "\n",
    "\n",
    "cell_voltage_list = list()\n",
    "cell_current_list = list()\n",
    "for gid in cell_gids:\n",
    "    voltage_list = list()\n",
    "    # Get voltages\n",
    "    voltage_list = [vsec for vsec in  net.cell_response.vsec[0][gid].values()]\n",
    "    cell_voltage_list.append(voltage_list)\n",
    "\n",
    "    current_list = list()\n",
    "    # Get currents\n",
    "    for sec_name in net.cell_response.isec[0][gid].keys():\n",
    "        current_list.extend([isec for isec in net.cell_response.isec[0][gid][sec_name].values()])\n",
    "\n",
    "    cell_current_list.append(current_list)\n",
    "\n",
    "# Recordings stored in shape (num_cells x num_rec_sites x time)\n",
    "cell_voltages = np.stack(cell_voltage_list)\n",
    "cell_currents = np.stack(cell_current_list)\n",
    "\n",
    "n_voltages = cell_voltages.shape[1]  # first n_volumns used as prediction target\n",
    "\n",
    "sim_data = np.concatenate([cell_voltages, cell_currents], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780c99e-372b-4b89-bd74-62488df5995c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c8ad950-8f4e-405b-bb8b-2f355b404d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiComp_Dataset(torch.utils.data.Dataset):\n",
    "    #'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, sim_data, n_voltages, data_step_size=1, window_size=10, scaler=None, device='cpu'):\n",
    "        self.sim_data = sim_data\n",
    "        self.n_voltages = n_voltages\n",
    "        self.data_step_size = data_step_size\n",
    "        self.window_size = window_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.n_cells, self.n_rec_sites, self.n_times = sim_data.shape\n",
    "        self.sim_data_unfolded = self.process_data(sim_data)\n",
    "        \n",
    "        if self.scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            self.scaler.fit(np.vstack(self.neuralData_list))\n",
    "        \n",
    "        # X is one step behind y\n",
    "        self.X_tensor = self.sim_data_unfolded[:, :-1, :]\n",
    "        self.y_tensor = self.sim_data_unfolded[:, 1:, :n_voltages]\n",
    "        assert self.X_tensor.shape[0] == self.y_tensor.shape[0]\n",
    "        self.num_samples = self.X_tensor.shape[0]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, slice_index):\n",
    "        return self.X_tensor[slice_index,:,:], self.y_tensor[slice_index,:,:]\n",
    "    \n",
    "    def process_data(self, sim_data):\n",
    "        sim_data_tensor = torch.from_numpy(sim_data[0]).transpose(0, 1)\n",
    "        sim_data_unfolded = sim_data_tensor.unfold(0, self.window_size + 1, self.data_step_size).transpose(1, 2)\n",
    "        return sim_data_unfolded\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28c17804-899e-4204-a01f-9ae8a3be87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(sim_data.shape[2] * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9ebbf-243e-41c8-8dc6-620fd5ca8838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e43bd-77c9-46d4-92ff-ae00516eb418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da1e92e2-de08-4529-a55a-d2a1905e3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = MultiComp_Dataset(sim_data[:,:,:train_size], n_voltages)\n",
    "validation_set = MultiComp_Dataset(sim_data[:,:,train_size:], n_voltages)\n",
    "\n",
    "_, _, input_size = training_set[:][0].numpy().shape\n",
    "_, _, output_size = training_set[:][1].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87674664-d71d-4fe5-a126-1b68ea3fc3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_lstm(input_size=input_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8082ac55-ca1f-4e6e-a1d1-64ceca3428a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "weight_decay = 1e-5\n",
    "max_epochs = 1000\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abc05c-0f36-4661-bc59-311b7f83269c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1adc3-b1c8-4e61-a6e7-c7ab5d44cca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ded30e20-58b7-4ec8-9ca7-069d4e14046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_cores = 32\n",
    "train_params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': num_cores, 'pin_memory':False}\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **train_params)\n",
    "\n",
    "validation_params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': num_cores, 'pin_memory':False}\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, **validation_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20619854-3a19-4e7e-a9e2-b762e6fc8585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****......\n",
      "Epoch: 10/1000 ... Train Loss: 79.3591  ... Validation Loss: 76.7248\n",
      " Early Stop; Min Epoch: 4\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "loss_dict = utils.train_validate_model(model, optimizer, criterion, max_epochs, training_generator, validation_generator, device, 10, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd88ea-1afc-4e4b-b62f-f9c2cc634045",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = utils.evaluate_model(model_ann, training_eval_generator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015aadf-be4a-4a20-a24d-c2507af99dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675e706-741c-4287-a7b4-d98fa92bb362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1bdede-52b7-4661-82f7-48d17ba0350c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f5549-699b-4757-951d-b005640267a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate trained model\n",
    "ann_train_pred = mocap_functions.evaluate_model(model_ann, training_eval_generator, device)\n",
    "ann_test_pred = mocap_functions.evaluate_model(model_ann, testing_generator, device)\n",
    "\n",
    "#Compute decoding performance\n",
    "ann_train_corr = mocap_functions.matrix_corr(ann_train_pred,y_train_data)\n",
    "ann_test_corr = mocap_functions.matrix_corr(ann_test_pred,y_test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4246d-8cfc-4649-ba92-aefaa204a7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17f52197-44b0-4ff5-8005-68ceb7163fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generate cv_dict for regular train/test/validate split (no rolling window)\n",
    "# cv_split = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
    "# val_split = ShuffleSplit(n_splits=1, test_size=.25, random_state=0)\n",
    "# cv_dict = {}\n",
    "# for fold, (train_val_idx, test_idx) in enumerate(cv_split.split(np.arange(num_trials))):\n",
    "#     for t_idx, v_idx in val_split.split(train_val_idx): #No looping, just used to split train/validation sets\n",
    "#         cv_dict[fold] = {'train_idx':train_val_idx[t_idx], \n",
    "#                          'test_idx':test_idx, \n",
    "#                          'validation_idx':train_val_idx[v_idx]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39faa9f-c933-4c8f-9682-5f94eaa4ab8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfn_2023",
   "language": "python",
   "name": "sfn_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
